{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Particle Swarm Optimization\n",
    "\n",
    "This exercise is about creating a particle swarm optimization (PSO) implementation that can solve simple 2D benchmark functions. Particle Swarm Optimization is a classical population based metaheuristic where the *candidate solutions* are defined as *particles*. Originally, PSO was inspired by bird flocking behavior where you can imagine each particle to be a bird and their behavior as a flock of birds to be the swarm that can optimize for foraging and other social behaviors. To get a basic understanding of how PSO works, in this exercise we will implement a very rudementary implentation based on the following PSO equation:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image \n",
    "Image(\"pso_equations.png\") # source : http://web.ist.utl.pt/gdgp/VA/pso.htm "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, each particle contains parameters of its *position* and *velocity*. The first equation basically states how the position of a particle is updated based on the velocity. \n",
    "In the second, you can see how the *velocity* (v) of a particle is updated each iteration based on the best position found by a single particle (*pb*; particle's best) plus the best position of all particles (*gb*; global best). The two constants, C1 and C2 (Acceleration Constants) affect the influence of *pb* and *gb* on the velocity of the particles. With these basic equations we can start creating a PSO algorithm. \n",
    "\n",
    "Note that how the algorithm for this exersize is based on mostly object oriented programming and by no means will this be the most efficient way of coding the algorithm up. Feel free to enhance the implementation as you see fit. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries\n",
    "\n",
    "We will be using some standard libraries including some that allow us to visualize the problem space in 3D and animate it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import copy \n",
    "\n",
    "from matplotlib import cm \n",
    "from mpl_toolkits.mplot3d import Axes3D     # 3D plotting \n",
    "from matplotlib import animation, rc        # animation\n",
    "from IPython.display import HTML\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimization functions\n",
    "\n",
    "Before implementing PSO, it's useful to already define the problem space. For this exercise we'll limit the problem to two dimensions and import two functions that are based on the Distributed Evolutionary Algorithms in Python (DEAP) optimization functions (https://deap.readthedocs.io/en/master/api/benchmarks.html). We'll use the Rastrigin and the Bohachevsky functions. We'll define these functions as objects with a static evaluation method that we can pass to our PSO implementation later. The evaluation functions will take in two positional coordinates (x and y) and will return a single fitness value. In addition, these functions have a lower and upper bound, so for simplicity, we'll define these parameters within the class objects as well. The functions that we are using are minimization functions so lower fitness values are better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Rastrigin:\n",
    "  lower_bound = -5.12\n",
    "  upper_bound = 5.12\n",
    "  @staticmethod # the evaluation function taking x and y as inputs\n",
    "  def evaluate(x,y):\n",
    "    return ((x**2 - 10 * np.cos(2 * np.pi * x)) + \\\n",
    "    (y**2 - 10 * np.cos(2 * np.pi * y)) + 20)\n",
    "\n",
    "class Bohachevsky: \n",
    "  lower_bound = -100\n",
    "  upper_bound = 100\n",
    "  @staticmethod \n",
    "  def evaluate(x,y):\n",
    "    return (x**2 + 2*y**2 - 0.3*np.cos(3*3.14*x) - 0.4*np.cos(4*3.14*y) + 0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To visualize the two optimization functions above, we can simply create X and Y values at intervals and evaluate these X,Y coordinates as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "om = Rastrigin # Change this to Bohachevsky to see the Bohachevsky solution space (om stands for optimization method)\n",
    "X = np.linspace(om.lower_bound, om.upper_bound, 100)     \n",
    "Y = np.linspace(om.lower_bound, om.upper_bound, 100)     \n",
    "X, Y = np.meshgrid(X, Y) \n",
    "Z = om.evaluate(X,Y)\n",
    "# Our Z axis (up) will represent the fitness values for the x,y coordinates. \n",
    "fig = plt.figure() \n",
    "ax = fig.gca(projection='3d') \n",
    "ax.plot_surface(X, Y, Z, rstride=1, cstride=1,\n",
    "  cmap=cm.inferno_r, linewidth=0.08,\n",
    "  alpha = 0.3)    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A simplified particle object\n",
    "\n",
    "Next up we can define a simple particle object that we can update iteratively. Each particle needs to contain information about its position (*self.pos*), its velocity (*self.vel*), it's fitness (*self.fitness*), it's best position (*p_best*) and it's best fitness (*self.best_fitness*). The positional and velocity vectors are simply defined as arrays that will contain 2 values (The first referring to x, the second to y). When we create a new particle instance, we want to give it a random position and evaluate it accordingly. The *__init__* therefore takes two arguments: the random position, and a reference to the optimization function. \n",
    "For the update function, we'll use the second equation stated above. This equation requires a parameter *gb*, the best solution found in the swarm hence we'll give the update function an argument g_best every time we update it. We'll also pass the reference to the optimization function again.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can you write down the velocity update function correctly accepting that g_best will be a vector containing two values (x and y)?. The function requires two constants C1 and C2 which you can define globally. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Particle:\n",
    "    def __init__(self,position,optimization_function_object):\n",
    "        self.pos = position\n",
    "        self.vel = np.asarray([random.uniform(-VELOCITY_MAGNITUDE,VELOCITY_MAGNITUDE),random.uniform(-VELOCITY_MAGNITUDE,VELOCITY_MAGNITUDE)])\n",
    "        self.p_best = copy.deepcopy(position)\n",
    "        self.fitness = optimization_function_object.evaluate(self.pos[0], self.pos[1])\n",
    "        self.best_fitness = self.fitness\n",
    "    def update(self,g_best, optimization_function_object):\n",
    "        # pick random numbers r1 and r2\n",
    "        r1,r2 = random.uniform(0,1),random.uniform(0,1)\n",
    "        # update particles velocity\n",
    "        self.vel = 0 # Adjust this function according to the equation above. You can find a working version in the solution file. \n",
    "        # update particle's position\n",
    "        self.pos = self.pos + self.vel\n",
    "        # ensure position is not out of bounds\n",
    "        if (self.pos[0] > optimization_function_object.upper_bound):\n",
    "            self.pos[0] = optimization_function_object.upper_bound\n",
    "        elif (self.pos[0] < optimization_function_object.lower_bound):\n",
    "            self.pos[0] = optimization_function_object.lower_bound\n",
    "        if (self.pos[1] > optimization_function_object.upper_bound):\n",
    "            self.pos[1] = optimization_function_object.upper_bound\n",
    "        elif (self.pos[1] < optimization_function_object.lower_bound):\n",
    "            self.pos[1] = optimization_function_object.lower_bound\n",
    "        # evaluate the performance of the particle\n",
    "        self.fitness = optimization_function_object.evaluate(self.pos[0],self.pos[1])\n",
    "        # If a better solutions has been found, the best_fitness and best position should be updated.\n",
    "        if (self.fitness < self.best_fitness):\n",
    "            self.best_fitness = self.fitness\n",
    "            self.p_best = copy.deepcopy(self.pos)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A simplified swarm object\n",
    "\n",
    "To encapsulate the individual particles, we can create a swarm object (the equavalent in evolutionary algorithms being a population). I have chosen to store the particles in a simple array and the reference to the optimization_function is stored in the instance as well. When creating a swarm, we pass an argument of the number of particles we want to simulate, and the optimization function we are using. To get the best particle in the swarm so far, we can simply iterate over all particles and keep track of which one is the best. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Swarm:\n",
    "    def __init__(self,n_particles, optimization_function):\n",
    "        self.particles = []\n",
    "        self.optimization_function = optimization_function\n",
    "        for i in range(n_particles):\n",
    "            # Initialize a random positional vector within the scope\n",
    "            LB = self.optimization_function.lower_bound\n",
    "            UB = self.optimization_function.upper_bound\n",
    "            pos = np.asarray([random.uniform(LB,UB),random.uniform(LB,UB)])\n",
    "            # Having a random.uniform distribution is perhaps a bit too easy to optimize. See what happens if you initialize particles in different parts of the search space: \n",
    "            # pos = np.asarray([random.uniform(LB,LB+2),random.uniform(LB,LB+2)])\n",
    "            # create a new particle instance\n",
    "            p = Particle(pos, self.optimization_function)\n",
    "            self.particles.append(p)\n",
    "        self.g_best = None\n",
    "        self.min_fit = 10000.0 # give a high value to the best solution initially so it will be overwritten\n",
    "        self.best(self.particles) # adjusts self's g_best and min_fit\n",
    "        \n",
    "    def best(self, particles, minimization = True):\n",
    "        # This is quite a hacky function and simply sets the g_best (position of the best particle value) if a new best fitness (min_fit) is found.\n",
    "        for p in particles:\n",
    "            if (p.fitness < self.min_fit):\n",
    "                self.min_fit = p.fitness\n",
    "                self.g_best = copy.deepcopy(p.p_best)\n",
    "        \n",
    "    def update(self):\n",
    "        positions = []\n",
    "        fitness_values = []\n",
    "        for p in self.particles:\n",
    "            p.update(self.g_best, self.optimization_function)\n",
    "            positions.append(p.pos)\n",
    "            fitness_values.append(p.fitness)\n",
    "        self.best(self.particles)\n",
    "        return positions,fitness_values\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the algorithm\n",
    "\n",
    "We are using some variables in our update functions that aren't defined yet so we'll start of by defining them globally. We need to define the acceleration coefficients (C1 and C2), and the *VELOCITY_MAGNITUDE*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C1 = 0.001 # acceleration coefficient 1\n",
    "C2 = 0.04 # acceleration coefficient 2\n",
    "VELOCITY_MAGNITUDE = 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can create and run the PSO method by creating a new swarm obect and calling the update function a few times. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "swarm = Swarm(50, Rastrigin) # the first argument sets the number of particles we are using, the second is the reference to the objective function\n",
    "for i in range(50):\n",
    "    swarm.update()\n",
    "    print(swarm.min_fit) # we can print the best solution found so far to ensure our algorithm is working"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you're like me, seeing the optimization algorithm working as above is not very insightful to understand how it works. To help us get a better understanding of how the algorithm traverses the search space, we can make a small animation using matplotlib that updates the X,Y and Z values of each particle by iterating through it. We can create a new swarm and update it accordingly while at the same time plotting the animation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "om = Rastrigin # Change this to Bohachevsky to see the Bohachevsky solution space\n",
    "\n",
    "# create a new PSO swarm\n",
    "swarm = Swarm(50, om)\n",
    "\n",
    "# To plot the landscape\n",
    "X = np.linspace(om.lower_bound, om.upper_bound, 100)     \n",
    "Y = np.linspace(om.lower_bound, om.upper_bound, 100)     \n",
    "X, Y = np.meshgrid(X, Y) \n",
    "Z = om.evaluate(X,Y)\n",
    "\n",
    "fig = plt.figure() \n",
    "ax = fig.gca(projection='3d') \n",
    "\n",
    "LB = swarm.optimization_function.lower_bound\n",
    "UB = swarm.optimization_function.upper_bound\n",
    "\n",
    "def update(frame, print_best = False):    \n",
    "    ax.clear()\n",
    "    position_values_x = []\n",
    "    position_values_y = []\n",
    "    positions, fitnesses = swarm.update()\n",
    "    for pos in positions:\n",
    "        position_values_x.append(pos[0])\n",
    "        position_values_y.append(pos[1])\n",
    "    ax.plot_surface(X, Y, Z, rstride=1, cstride=1, cmap=cm.inferno, linewidth=0.08, alpha = 0.1)\n",
    "    ax.set_xlim(LB,UB)\n",
    "    ax.set_ylim(LB,UB)\n",
    "    ax.set_zlim(0.0,100)\n",
    "    ax.scatter(position_values_x, position_values_y,fitnesses,c=fitnesses)\n",
    "    if print_best:\n",
    "        print(\"Highest fitness is \" ,swarm.max_fit, \" at \", swarm.g_best)\n",
    "\n",
    "n_iterations = 50 # the number of iterations\n",
    "interval = 20 # \n",
    "anim = animation.FuncAnimation(fig, update, frames=np.arange(n_iterations), interval=interval)\n",
    "HTML(anim.to_jshtml())"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.6.4-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python36432bitec457a294f9648d7b4b468483e61d6f5",
   "display_name": "Python 3.6.4 32-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}